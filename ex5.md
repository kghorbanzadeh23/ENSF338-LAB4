# Exercise 5

# 1
### timeit.timeit() with number parameter: This method aims to reduce noise by executing the code multiple times within a single timing measurement. By specifying the number parameter, you can control how many times the code is executed per timing measurement. This approach helps mitigate some issues like warm-up effects and statistical variability by averaging over multiple executions. timeit.repeat(): This function runs the code snippet for a specified number of times (controlled by the repeat parameter) and provides a list of execution times for each run. It addresses the issue of statistical variability more explicitly by running the code multiple times and allowing you to analyze the distribution of execution times. This method provides a more robust estimate of the execution time, especially in scenarios where there is significant variability between runs. Use timeit.timeit() with the number parameter when you're primarily interested in the average time taken for a single execution of the code snippet. This approach is suitable for quickly getting an estimate of the code's performance. Use timeit.repeat() when you want a more comprehensive analysis of the code's execution time, especially if there's significant variability between runs. This method allows you to study the distribution of execution times and provides a better understanding of the code's performance characteristics, making it suitable for more in-depth performance analysis and benchmarking.

# 2
### When using timeit.timeit(), which measures the time taken for a single execution (or a specified number of executions) of the code snippet, the appropriate statistic to apply is the average. This is because timeit.timeit() provides a single measurement representing the total time taken for all executions. Dividing this total time by the number of executions gives the average time taken per execution. On the other hand, when using timeit.repeat(), which runs the code snippet for a specified number of times and provides a list of execution times for each run, the appropriate statistics to apply are the minimum, maximum, and average. Minimum: Represents the shortest execution time observed among all runs. It provides insight into the best-case scenario or the fastest the code can execute under given conditions. Maximum: Represents the longest execution time observed among all runs. It indicates the worst-case scenario or the slowest the code can execute under given conditions. Average: Represents the average execution time across all runs. It gives a general idea of the typical performance of the code. Using the minimum and maximum alongside the average allows for a more comprehensive understanding of the code's performance characteristics, including its variability and extremes. This is particularly important when analyzing the reliability and consistency of the code's execution time, as well as understanding the potential range of performance outcomes in different scenarios.